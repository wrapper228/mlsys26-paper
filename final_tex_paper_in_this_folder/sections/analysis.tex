\section{Первый важный вывод про процесс изменения эмбеддингов}
Используя формулу \(\Delta q_i = -\eta\sum_j J_i J_j^{\top} g_j\), видно, что вклад каждого примера батча взвешивается матрицей \(J_i J_j^{\top}\). В частном случае, когда \(J_i J_j^{\top}\) мало для \(i\ne j\), приращение \(\Delta q_i\) определяется собственным градиентом \(g_i\).

\section{Что такое энкодер, линейный по параметрам}
Назовём энкодер линейным по параметрам, если выход можно записать как
\[
q(\theta, x) = J(x)\,\theta,
\]
где матрица \(J(x)\) зависит только от входа \(x\) (и гиперпараметров), но не от \(\theta\). Тогда \(J\) не меняется при обновлении параметров, и линейная аппроксимация становится точной.

\section{Какие архитектуры линейны по параметрам}
Классические примеры: линейные слои/эмбеддинг-таблицы без параметризованных нормализаций/активаций, а также композиции фиксированных преобразований входа с одним линейным слоем по параметрам. В этих случаях \(q\) зависит от \(\theta\) аффинно/линейно.

\section{Пример архитектуры, не линейной по параметрам}
Многослойный персептрон с нелинейностями и несколькими обучаемыми слоями порождает произведения параметров разных слоёв, поэтому зависимость \(q(\theta,x)\) от \(\theta\) нелинейна.

\section{Когда \(\Delta q_i\) коллинеарно \(g_i\)}
Если (приблизительно) \(J_i J_i^{\top} \propto I\) и перекрёстные члены \(J_i J_j^{\top}\) малы при \(j\ne i\), тогда
\[
\Delta q_i \approx -\eta\, J_i J_i^{\top} g_i \propto -g_i,
\]
то есть изменение эмбеддинга сонаправлено (с противоположным знаком) градиенту лосса по выходу.

\section{Градиент косинусного лосса ортогонален выходу}
Для \(s(q,k)=\tfrac{q^{\top}k}{\|q\|\,\|k\|}\) выполняется \(q^{\top}\,\partial s/\partial q = 0\). Следовательно, для классов лоссов, производных от косинусной близости, \(g=\partial \mathcal{L}/\partial q\) лежит в касательной плоскости к сфере \(\|q\|=\text{const}\) и ортогонален \(q\).

\section{Когда появляется ортогональное движение}
Ортогональность \(g\) к \(q\) не гарантирует ортогональность \(\Delta q\) к \(q\). Необходимо, чтобы \(J_i J_j^{\top}\) не вносили компонент вдоль \(q_i\). При линейных по параметрам энкодерах и «почти диагональном» \(J_i J_j^{\top}\) ортогональное движение возникает чаще.

\section{Связь с работами об ортогональности}
Ряд работ анализирует ортогональные компоненты градиентов при косинусных целях, однако практические энкодеры нарушают предпосылки (например, из-за архитектуры/нормализаций), что меняет проекцию \(\Delta q\).

\section{Зависимость нормы от популярности}
Интуитивно, чем чаще объект встречается как положительный пример, тем чаще он получает обновления, которые (через структуру \(J_i J_j^{\top}\)) добавляют компонент вдоль текущего \(q_i\) или в стабильных направлениях, что ведёт к росту \(\|q_i\|\), даже если при инференсе используется косинус. Это приводит к корреляции нормы с популярностью и систематическому смещению при ранжировании по скалярному произведению.
